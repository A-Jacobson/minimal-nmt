{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_text(sequence, field):\n",
    "    pad = field.vocab.stoi['<pad>']\n",
    "    return \" \".join([field.vocab.itos[int(i)] for i in sequence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Multi30k English/German parallel corpus for NMT\n",
    "TorchText takes care of tokenization, padding,  special character tokens and batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(batch_size, device=0):\n",
    "    spacy_de = spacy.load('de')\n",
    "    spacy_en = spacy.load('en')\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "    DE = Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>')\n",
    "    EN = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "    train, val, test = Multi30k.splits(exts=('.de', '.en'), fields=(DE, EN))\n",
    "\n",
    "    DE.build_vocab(train.src)\n",
    "    EN.build_vocab(train.trg)\n",
    "\n",
    "    train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (train, val, test), batch_size=batch_size, device=device, repeat=False)\n",
    "    return train_iter, val_iter, test_iter, DE, EN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inputs\n",
    "Model inputs are (seq_len, batch_size) Tensors of word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "      2      2      2      2      2\n",
       "      5      5    129    126     21\n",
       "     12    441     85    210     67\n",
       "  16126     48     31    199    141\n",
       "     37    683   2279    169     10\n",
       "     13    768     25     39   2637\n",
       "  13614      8     10    335     43\n",
       "      8     43      6      9     44\n",
       "      6     18   2105     61    611\n",
       "    497    785     22     23      9\n",
       "    166     29   1941   1134    191\n",
       "   8660    236    318    119  10878\n",
       "      4      4      4      4      4\n",
       "      3      3      3      3      3\n",
       " [torch.LongTensor of size 14x5], Variable containing:\n",
       "      2      2      2      2      2\n",
       "    111     49    145     49     19\n",
       "   8994    195     25    128     25\n",
       "    163    109     36      7     73\n",
       "  10256     10    757     95    764\n",
       "     18    254      4     10    174\n",
       "     25     18   5277     42      8\n",
       "    158    333      7    236    272\n",
       "    233      9      8    438     46\n",
       "  10217      4   1053     46    377\n",
       "   1992    730    325    374    776\n",
       "      5      5      5      5      5\n",
       "      3      3      3      3      3\n",
       " [torch.LongTensor of size 13x5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter, DE, EN = load_dataset(batch_size=5, device=-1)\n",
    "example_batch = next(iter(train_iter))\n",
    "example_batch.src, example_batch.trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can recover the original text by looking up each index in the vocabularies we build with the `load_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> Ein Mann bestimmt w√§hrend einer Schneeschuhwanderungen , einem jungen Paar Baumarten . <eos>\n",
      "<sos> Man identifying tree species to young couple during snowshoeing trip . <eos>\n"
     ]
    }
   ],
   "source": [
    "print(sequence_to_text(example_batch.src[:, 0], DE))\n",
    "print(sequence_to_text(example_batch.trg[:, 0], EN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture \n",
    "NMT uses an encoder-decoder architecture to effectively translate source sequences and target sequences that are of different lengths\n",
    "![img](assets/encoder-decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encodes each word of the source sequence into a `hidden_dim` feature map. Sometimes called an `annotation`. Also returns the hidden state of the encoder bi-rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, source_vocab_size, embed_dim, hidden_dim,\n",
    "                 n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = nn.Embedding(source_vocab_size, embed_dim, padding_idx=1)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, n_layers,\n",
    "                          dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, source, hidden=None):\n",
    "        embedded = self.embed(source)  # (batch_size, seq_len, embed_dim)\n",
    "        encoder_out, encoder_hidden = self.gru(\n",
    "            embedded, hidden)  # (seq_len, batch, hidden_dim*2)\n",
    "        # sum bidirectional outputs, the other option is to retain concat features\n",
    "        encoder_out = (encoder_out[:, :, :self.hidden_dim] +\n",
    "                       encoder_out[:, :, self.hidden_dim:])\n",
    "        return encoder_out, encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(source_vocab_size=len(DE.vocab), embed_dim=embed_dim,\n",
    "                  hidden_dim=hidden_dim, n_layers=n_layers, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output size:  torch.Size([14, 5, 512])\n",
      "encoder hidden size:  torch.Size([4, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "encoder_out, encoder_hidden = encoder(example_batch.src)\n",
    "print('encoder output size: ', encoder_out.size())  # source, batch_size, hidden_dim\n",
    "print('encoder hidden size: ', encoder_hidden.size()) # n_layers * num_directions, batch_size, hidden_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "Currently the `encoder_output` is a length 14 sequence and the target is a length 13 sequence. We need to compress the information in the `encoder_output` into a `context_vector` which should have all the information the decoder needs to predict the next step of its output. We will use `Luong Attention` to create this context vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    LuongAttention from Effective Approaches to Attention-based Neural Machine Translation\n",
    "    https://arxiv.org/pdf/1508.04025.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.W = nn.Linear(dim, dim, bias=False)\n",
    "\n",
    "    def score(self, decoder_hidden, encoder_out):\n",
    "        # linear transform encoder out (seq, batch, dim)\n",
    "        encoder_out = self.W(encoder_out)\n",
    "        # (batch, seq, dim) | (2, 15, 50)\n",
    "        encoder_out = encoder_out.permute(1, 0, 2)\n",
    "        # (2, 15, 50) @ (2, 50, 1)\n",
    "        return encoder_out @ decoder_hidden.permute(1, 2, 0)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_out):\n",
    "        energies = self.score(decoder_hidden, encoder_out)\n",
    "        mask = F.softmax(energies, dim=1)  # batch, seq, 1\n",
    "        context = encoder_out.permute(\n",
    "            1, 2, 0) @ mask  # (2, 50, 15) @ (2, 15, 1)\n",
    "        context = context.permute(2, 0, 1)  # (seq, batch, dim)\n",
    "        mask = mask.permute(2, 0, 1)  # (seq2, batch, seq1)\n",
    "        return context, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will normally be part of the decoder as it takes the previous decoder hidden state as input, but just to show the inputs and outputs I will use it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize the Decoder rnn's hidden state with the last hidden state from the encoder. Because the encoder is bi-directional we have to reshape it's hidden state in order to select the layer we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 512])\n",
      "torch.Size([1, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "attention = LuongAttention(dim=hidden_dim)\n",
    "context, mask = attention(encoder_hidden[-1:], encoder_out)\n",
    "print(context.size()) # (1, batch, attention_dim) contect_vector\n",
    "print(mask.size())  # the weights used to compute weighted sum over encoder out (1, batch, source_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, target_vocab_size, embed_dim, hidden_dim,\n",
    "                 n_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(target_vocab_size, embed_dim, padding_idx=1)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "        self.gru = nn.GRU(embed_dim + hidden_dim, hidden_dim, n_layers,\n",
    "                          dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_dim * 2, target_vocab_size)\n",
    "\n",
    "    def forward(self, output, encoder_out, decoder_hidden):\n",
    "        \"\"\"\n",
    "        decodes one output frame\n",
    "        \"\"\"\n",
    "        embedded = self.embed(output)  # (1, batch, embed_dim)\n",
    "        context, mask = self.attention(decoder_hidden[:-1], encoder_out)  # 1, 1, 50 (seq, batch, hidden_dim)\n",
    "        rnn_output, decoder_hidden = self.gru(torch.cat([embedded, context], dim=2),\n",
    "                                              decoder_hidden)\n",
    "        output = self.out(torch.cat([rnn_output, context], 2))\n",
    "        return output, decoder_hidden, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(target_vocab_size=len(EN.vocab), embed_dim=embed_dim,\n",
    "                  hidden_dim=hidden_dim, n_layers=n_layers, dropout=dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To translate one word from German to English, the decoder needs:\n",
    "1. `encoder_outputs`\n",
    "2. `decoder_hidden` initially, the last n_layers of encoder_hidden then it's own returned hidden state.\n",
    "3. `previous_output` feed a batch of start of string token (index 2) at the first step.\n",
    "\n",
    "The attention mask that the decoder returns is not used in training but can be used to visualize where the decoder is \"looking\" in the input sequence in order to generate its current output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2  2  2  2  2\n",
       "[torch.LongTensor of size 1x5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_hidden = encoder_hidden[-decoder.n_layers:]\n",
    "start_token = example_batch.trg[:1]\n",
    "start_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, decoder_hidden, mask = decoder(start_token, encoder_out, decoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([1, 5, 10839])\n",
      "decoder hidden size  torch.Size([2, 5, 512])\n",
      "attention mask size torch.Size([1, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "print('output size: ', output.size())  # (1, batch, target_vocab) # predicted probability distribution over all possible target words\n",
    "print('decoder hidden size ', decoder_hidden.size())\n",
    "print('attention mask size', mask.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Helpers\n",
    "nmt models use teacher forcing during training and greedy decoding or beam search for inference. In order to accommodate these behaviors, I've made simple helper classes that get output from the decoder using each policy.\n",
    "\n",
    "The Teacher class sometimes feeds the previous target to the decoder rather than the model's previous prediction. this can help speed convergence but requires targets to be loaded to the helper at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher:\n",
    "    def __init__(self, teacher_forcing_ratio=0.5):\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.targets = None\n",
    "        self.maxlen = 0\n",
    "        \n",
    "    def load_targets(self, targets):\n",
    "        self.targets = targets\n",
    "        self.maxlen = len(targets)\n",
    "\n",
    "    def generate(self, decoder, encoder_out, encoder_hidden):\n",
    "        outputs = []\n",
    "        masks = []\n",
    "        decoder_hidden = encoder_hidden[-decoder.n_layers:]  # take what we need from encoder\n",
    "        output = self.targets[0].unsqueeze(0)  # start token\n",
    "        for t in range(1, self.maxlen):\n",
    "            output, decoder_hidden, mask = decoder(output, encoder_out, decoder_hidden)\n",
    "            outputs.append(output)\n",
    "            masks.append(mask.data)\n",
    "            output = Variable(output.data.max(dim=2)[1])\n",
    "            # teacher forcing\n",
    "            is_teacher = random.random() < self.teacher_forcing_ratio\n",
    "            if is_teacher:\n",
    "                output = self.targets[t].unsqueeze(0)      \n",
    "        return torch.cat(outputs), torch.cat(masks).permute(1, 2, 0)  # batch, src, trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_helper = Teacher()\n",
    "decode_helper.load_targets(example_batch.trg)\n",
    "outputs, masks = decode_helper.generate(decoder, encoder_out, encoder_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc loss\n",
    "reshape outputs and targets, ignore sos token at start of target batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 9.2886\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(outputs.view(-1, outputs.size(2)),\n",
    "                           example_batch.trg[1:].view(-1), ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greedy decoder simply chooses the highest scoring word as output.\n",
    "We cam use the `set_maxlen` method to generate sequences the same length as our targets to easily check perplexity and bleu score during evaluation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Greedy:\n",
    "    def __init__(self, maxlen=20, sos_index=2):\n",
    "        self.maxlen = maxlen\n",
    "        self.sos_index = sos_index\n",
    "        \n",
    "    def set_maxlen(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    def generate(self, decoder, encoder_out, encoder_hidden):\n",
    "        seq, batch, _ = encoder_out.size()\n",
    "        outputs = []\n",
    "        masks = []\n",
    "        decoder_hidden = encoder_hidden[-decoder.n_layers:]  # take what we need from encoder\n",
    "        output = Variable(torch.zeros(1, batch).long() + self.sos_index)  # start token\n",
    "        for t in range(self.maxlen):\n",
    "            output, decoder_hidden, mask = decoder(output, encoder_out, decoder_hidden)\n",
    "            outputs.append(output)\n",
    "            masks.append(mask.data)\n",
    "            output = Variable(output.data.max(dim=2)[1])\n",
    "        return torch.cat(outputs), torch.cat(masks).permute(1, 2, 0)  # batch, src, trg     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_helper = Greedy()\n",
    "decode_helper.set_maxlen(len(example_batch.trg[1:]))\n",
    "outputs, masks = decode_helper.generate(decoder, encoder_out, encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 5, 10839])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 9.2933\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(outputs.view(-1, outputs.size(2)),\n",
    "                           example_batch.trg[1:].view(-1), ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, decoding_helper):\n",
    "        encoder_out, encoder_hidden = self.encoder(source)\n",
    "        outputs, masks = decoding_helper.generate(self.decoder, encoder_out, encoder_hidden)\n",
    "        return outputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(encoder, decoder)\n",
    "decoding_helper = Teacher(teacher_forcing_ratio=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example iteration with wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_helper.load_targets(example_batch.trg)\n",
    "outputs, masks = seq2seq(example_batch.src, decode_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 5, 10839]), torch.Size([5, 14, 12]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size(), masks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 9.2955\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(outputs.view(-1, outputs.size(2)),\n",
    "                           example_batch.trg[1:].view(-1), ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
